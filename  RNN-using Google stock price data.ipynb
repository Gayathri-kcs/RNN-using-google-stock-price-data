{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"C:\\\\Users\\\\user\\\\Downloads\\\\Google_Stock_Price_Train.csv\")\n",
    "\n",
    "# predict the stock for year 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>12/23/2016</td>\n",
       "      <td>790.90</td>\n",
       "      <td>792.74</td>\n",
       "      <td>787.28</td>\n",
       "      <td>789.91</td>\n",
       "      <td>623,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>12/27/2016</td>\n",
       "      <td>790.68</td>\n",
       "      <td>797.86</td>\n",
       "      <td>787.66</td>\n",
       "      <td>791.55</td>\n",
       "      <td>789,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>12/28/2016</td>\n",
       "      <td>793.70</td>\n",
       "      <td>794.23</td>\n",
       "      <td>783.20</td>\n",
       "      <td>785.05</td>\n",
       "      <td>1,153,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>12/29/2016</td>\n",
       "      <td>783.33</td>\n",
       "      <td>785.93</td>\n",
       "      <td>778.92</td>\n",
       "      <td>782.79</td>\n",
       "      <td>744,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>12/30/2016</td>\n",
       "      <td>782.75</td>\n",
       "      <td>782.78</td>\n",
       "      <td>770.41</td>\n",
       "      <td>771.82</td>\n",
       "      <td>1,770,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Open    High     Low   Close      Volume\n",
       "0       1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
       "1       1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
       "2       1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
       "3       1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
       "4       1/9/2012  322.04  322.29  309.46  620.76  11,688,800\n",
       "...          ...     ...     ...     ...     ...         ...\n",
       "1253  12/23/2016  790.90  792.74  787.28  789.91     623,400\n",
       "1254  12/27/2016  790.68  797.86  787.66  791.55     789,100\n",
       "1255  12/28/2016  793.70  794.23  783.20  785.05   1,153,800\n",
       "1256  12/29/2016  783.33  785.93  778.92  782.79     744,300\n",
       "1257  12/30/2016  782.75  782.78  770.41  771.82   1,770,000\n",
       "\n",
       "[1258 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       325.25\n",
       "1       331.27\n",
       "2       329.83\n",
       "3       328.34\n",
       "4       322.04\n",
       "         ...  \n",
       "1253    790.90\n",
       "1254    790.68\n",
       "1255    793.70\n",
       "1256    783.33\n",
       "1257    782.75\n",
       "Name: Open, Length: 1258, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_open = train['Open']\n",
    "dataset_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i will consider my input and outpur variable from same column \n",
    "# i will be taking last few days data as input varailabe say last 60 observation are inputs.\n",
    "#Input varilable 0 - 59  Output varilable : 60 \n",
    "#                1 - 60                   : 61\n",
    "#                2 - 61                   : 62\n",
    "#               3 - 62                    :  63\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are focus is only open column so we will consider only that column for stock analysis\n",
    "train=train.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[325.25],\n",
       "       [331.27],\n",
       "       [329.83],\n",
       "       ...,\n",
       "       [793.7 ],\n",
       "       [783.33],\n",
       "       [782.75]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc=MinMaxScaler()\n",
    "train=sc.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08581368],\n",
       "       [0.09701243],\n",
       "       [0.09433366],\n",
       "       ...,\n",
       "       [0.95725128],\n",
       "       [0.93796041],\n",
       "       [0.93688146]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list for xtrain and Ytrain\n",
    "\n",
    "x_train=[]\n",
    "y_train=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(60,1258):\n",
    "    x_train.append(train[i-60:i,:])\n",
    "    y_train.append(train[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1198, 60, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape # ( rows, input in each row ,column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1198, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init the NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape = num of independent variables \n",
    "# unit = number of output from Layers \n",
    "# Return Sequence will tell whether we are adding one more layer or not \n",
    "model.add(LSTM(return_sequences=True,input_shape=(x_train.shape[1],1),units=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM have more chances of Overfitting \n",
    "# dropout layer will remove some neurons which are causing Overfitting problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have same context in cell then there is chances of Over fitting to so we have to remove that using Drop out \n",
    "# Drop out will remove some unwanted neurons \n",
    "\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# its hidden layer so we dont pass input shape and Adding the multiple Hidden layer\n",
    "\n",
    "model.add(LSTM(return_sequences=True,units=50))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(return_sequences=True,units=50))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(return_sequences=False,units=50))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to add activation function but data am adding here is related to regression model and if we user activatoin fucnction relu\n",
    "# it will give only positive value but thats not correct way because am fine with out put negative also \n",
    "\n",
    "model.add(Dense(kernel_initializer=\"random_uniform\",units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary cross entory for binary \n",
    "#for regression we will use LSE \n",
    "# optimizer tells method how to update the weights using Gradient Descent Method\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\",optimizer=\"adam\",metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "38/38 [==============================] - 22s 101ms/step - loss: 315569.6835 - mse: 315569.6835\n",
      "Epoch 2/50\n",
      "38/38 [==============================] - 4s 113ms/step - loss: 309004.2821 - mse: 309004.2821\n",
      "Epoch 3/50\n",
      "38/38 [==============================] - 4s 113ms/step - loss: 316557.5841 - mse: 316557.5841\n",
      "Epoch 4/50\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 311206.5489 - mse: 311206.5489\n",
      "Epoch 5/50\n",
      "38/38 [==============================] - 4s 119ms/step - loss: 308207.0064 - mse: 308207.0064 0s - loss: 308235.2467 - mse: 308235.246\n",
      "Epoch 6/50\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 300031.9744 - mse: 300031.9744\n",
      "Epoch 7/50\n",
      "38/38 [==============================] - 6s 148ms/step - loss: 306003.1306 - mse: 306003.1306\n",
      "Epoch 8/50\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 301630.3670 - mse: 301630.3670\n",
      "Epoch 9/50\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 297611.7957 - mse: 297611.7957\n",
      "Epoch 10/50\n",
      "38/38 [==============================] - 4s 112ms/step - loss: 295231.1931 - mse: 295231.1931\n",
      "Epoch 11/50\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 299024.5785 - mse: 299024.5785\n",
      "Epoch 12/50\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 300165.2091 - mse: 300165.2091\n",
      "Epoch 13/50\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 296155.1034 - mse: 296155.1034\n",
      "Epoch 14/50\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 285991.1018 - mse: 285991.1018\n",
      "Epoch 15/50\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 288706.2772 - mse: 288706.2772 1s - loss: 289670.1690 - mse:\n",
      "Epoch 16/50\n",
      "38/38 [==============================] - 4s 100ms/step - loss: 283947.1490 - mse: 283947.1490\n",
      "Epoch 17/50\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 281840.0946 - mse: 281840.0946 0s - loss: 281561.7823 - mse: 281\n",
      "Epoch 18/50\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 275326.1558 - mse: 275326.1558\n",
      "Epoch 19/50\n",
      "38/38 [==============================] - 4s 100ms/step - loss: 279251.9760 - mse: 279251.9760\n",
      "Epoch 20/50\n",
      "38/38 [==============================] - 4s 100ms/step - loss: 283926.0417 - mse: 283926.0417\n",
      "Epoch 21/50\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 273163.8614 - mse: 273163.8614\n",
      "Epoch 22/50\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 281730.5793 - mse: 281730.5793\n",
      "Epoch 23/50\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 271260.1450 - mse: 271260.1450\n",
      "Epoch 24/50\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 266911.0633 - mse: 266911.0633\n",
      "Epoch 25/50\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 265418.1478 - mse: 265418.1478\n",
      "Epoch 26/50\n",
      "38/38 [==============================] - 4s 104ms/step - loss: 268177.0321 - mse: 268177.0321\n",
      "Epoch 27/50\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 260458.5966 - mse: 260458.5966\n",
      "Epoch 28/50\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 267914.3029 - mse: 267914.3029\n",
      "Epoch 29/50\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 263005.4407 - mse: 263005.4407\n",
      "Epoch 30/50\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 264226.9716 - mse: 264226.9716\n",
      "Epoch 31/50\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 263266.6895 - mse: 263266.6895\n",
      "Epoch 32/50\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 258562.3970 - mse: 258562.3970\n",
      "Epoch 33/50\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 250902.6274 - mse: 250902.6274\n",
      "Epoch 34/50\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 251361.9155 - mse: 251361.9155\n",
      "Epoch 35/50\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 244068.8025 - mse: 244068.8025\n",
      "Epoch 36/50\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 249589.6983 - mse: 249589.6983\n",
      "Epoch 37/50\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 244527.3738 - mse: 244527.3738\n",
      "Epoch 38/50\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 245648.4459 - mse: 245648.4459\n",
      "Epoch 39/50\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 236455.2552 - mse: 236455.2552\n",
      "Epoch 40/50\n",
      "38/38 [==============================] - 4s 100ms/step - loss: 247664.7151 - mse: 247664.7151\n",
      "Epoch 41/50\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 241835.4207 - mse: 241835.4207\n",
      "Epoch 42/50\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 233866.7163 - mse: 233866.7163\n",
      "Epoch 43/50\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 238163.3001 - mse: 238163.3001\n",
      "Epoch 44/50\n",
      "38/38 [==============================] - 4s 105ms/step - loss: 235759.7744 - mse: 235759.7744\n",
      "Epoch 45/50\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 232686.9207 - mse: 232686.9207 2s - loss: 2357\n",
      "Epoch 46/50\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 230362.6282 - mse: 230362.6282\n",
      "Epoch 47/50\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 230351.4291 - mse: 230351.4291\n",
      "Epoch 48/50\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 224967.0240 - mse: 224967.0240\n",
      "Epoch 49/50\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 226091.8113 - mse: 226091.8113\n",
      "Epoch 50/50\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 230080.4479 - mse: 230080.4479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x230516e1940>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 50, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x23048dac280>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"C:\\\\Users\\\\user\\\\Downloads\\\\Stock_Price_Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv(\"C:\\\\Users\\\\user\\\\Downloads\\\\Google_Stock_Price_Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.concat([train_data,test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1/25/2017</td>\n",
       "      <td>829.62</td>\n",
       "      <td>835.77</td>\n",
       "      <td>825.06</td>\n",
       "      <td>835.67</td>\n",
       "      <td>1,494,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1/26/2017</td>\n",
       "      <td>837.81</td>\n",
       "      <td>838.00</td>\n",
       "      <td>827.01</td>\n",
       "      <td>832.15</td>\n",
       "      <td>2,973,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1/27/2017</td>\n",
       "      <td>834.71</td>\n",
       "      <td>841.95</td>\n",
       "      <td>820.44</td>\n",
       "      <td>823.31</td>\n",
       "      <td>2,965,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1/30/2017</td>\n",
       "      <td>814.66</td>\n",
       "      <td>815.84</td>\n",
       "      <td>799.80</td>\n",
       "      <td>802.32</td>\n",
       "      <td>3,246,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1/31/2017</td>\n",
       "      <td>796.86</td>\n",
       "      <td>801.25</td>\n",
       "      <td>790.52</td>\n",
       "      <td>796.79</td>\n",
       "      <td>2,160,600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1278 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Open    High     Low   Close      Volume\n",
       "0    1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
       "1    1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
       "2    1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
       "3    1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
       "4    1/9/2012  322.04  322.29  309.46  620.76  11,688,800\n",
       "..        ...     ...     ...     ...     ...         ...\n",
       "15  1/25/2017  829.62  835.77  825.06  835.67   1,494,500\n",
       "16  1/26/2017  837.81  838.00  827.01  832.15   2,973,900\n",
       "17  1/27/2017  834.71  841.95  820.44  823.31   2,965,800\n",
       "18  1/30/2017  814.66  815.84  799.80  802.32   3,246,600\n",
       "19  1/31/2017  796.86  801.25  790.52  796.79   2,160,600\n",
       "\n",
       "[1278 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1198"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)-len(test_data)-60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last 60 values from train data and 20 from Test Data \n",
    "\n",
    "test=dataset.iloc[len(dataset)-len(test_data)-60:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>10/6/2016</td>\n",
       "      <td>779.00</td>\n",
       "      <td>780.48</td>\n",
       "      <td>775.54</td>\n",
       "      <td>776.86</td>\n",
       "      <td>1,070,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>10/7/2016</td>\n",
       "      <td>779.66</td>\n",
       "      <td>779.66</td>\n",
       "      <td>770.75</td>\n",
       "      <td>775.08</td>\n",
       "      <td>933,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>10/10/2016</td>\n",
       "      <td>777.71</td>\n",
       "      <td>789.38</td>\n",
       "      <td>775.87</td>\n",
       "      <td>785.94</td>\n",
       "      <td>1,174,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>10/11/2016</td>\n",
       "      <td>786.66</td>\n",
       "      <td>792.28</td>\n",
       "      <td>780.58</td>\n",
       "      <td>783.07</td>\n",
       "      <td>1,372,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>10/12/2016</td>\n",
       "      <td>783.76</td>\n",
       "      <td>788.13</td>\n",
       "      <td>782.06</td>\n",
       "      <td>786.14</td>\n",
       "      <td>937,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1/25/2017</td>\n",
       "      <td>829.62</td>\n",
       "      <td>835.77</td>\n",
       "      <td>825.06</td>\n",
       "      <td>835.67</td>\n",
       "      <td>1,494,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1/26/2017</td>\n",
       "      <td>837.81</td>\n",
       "      <td>838.00</td>\n",
       "      <td>827.01</td>\n",
       "      <td>832.15</td>\n",
       "      <td>2,973,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1/27/2017</td>\n",
       "      <td>834.71</td>\n",
       "      <td>841.95</td>\n",
       "      <td>820.44</td>\n",
       "      <td>823.31</td>\n",
       "      <td>2,965,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1/30/2017</td>\n",
       "      <td>814.66</td>\n",
       "      <td>815.84</td>\n",
       "      <td>799.80</td>\n",
       "      <td>802.32</td>\n",
       "      <td>3,246,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1/31/2017</td>\n",
       "      <td>796.86</td>\n",
       "      <td>801.25</td>\n",
       "      <td>790.52</td>\n",
       "      <td>796.79</td>\n",
       "      <td>2,160,600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Open    High     Low   Close     Volume\n",
       "1198   10/6/2016  779.00  780.48  775.54  776.86  1,070,700\n",
       "1199   10/7/2016  779.66  779.66  770.75  775.08    933,200\n",
       "1200  10/10/2016  777.71  789.38  775.87  785.94  1,174,900\n",
       "1201  10/11/2016  786.66  792.28  780.58  783.07  1,372,500\n",
       "1202  10/12/2016  783.76  788.13  782.06  786.14    937,400\n",
       "...          ...     ...     ...     ...     ...        ...\n",
       "15     1/25/2017  829.62  835.77  825.06  835.67  1,494,500\n",
       "16     1/26/2017  837.81  838.00  827.01  832.15  2,973,900\n",
       "17     1/27/2017  834.71  841.95  820.44  823.31  2,965,800\n",
       "18     1/30/2017  814.66  815.84  799.80  802.32  3,246,600\n",
       "19     1/31/2017  796.86  801.25  790.52  796.79  2,160,600\n",
       "\n",
       "[80 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test[\"Open\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.reshape(80,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=sc.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=[]\n",
    "y_test=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(60,80):\n",
    "    x_test.append(test[i-60:i,:])\n",
    "    y_test.append(test[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=np.array(x_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 60, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[95.88899],\n",
       "       [95.88899],\n",
       "       [95.88899],\n",
       "       [95.88899],\n",
       "       [95.88899],\n",
       "       [95.88899],\n",
       "       [95.88899],\n",
       "       [95.88899],\n",
       "       [95.88899],\n",
       "       [95.88899],\n",
       "       [95.88899],\n",
       "       [95.889  ],\n",
       "       [95.88899],\n",
       "       [95.88899],\n",
       "       [95.88899],\n",
       "       [95.88899],\n",
       "       [95.88899],\n",
       "       [95.88899],\n",
       "       [95.88899],\n",
       "       [95.889  ]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36708861],\n",
       "       [0.46953443],\n",
       "       [0.44507616],\n",
       "       [0.54355289],\n",
       "       [0.66305514],\n",
       "       [0.67871701],\n",
       "       [0.6480369 ],\n",
       "       [0.67099335],\n",
       "       [0.67464064],\n",
       "       [0.67034971],\n",
       "       [0.65672602],\n",
       "       [0.64932418],\n",
       "       [0.66852607],\n",
       "       [0.67217335],\n",
       "       [0.83361939],\n",
       "       [0.91214332],\n",
       "       [1.        ],\n",
       "       [0.96674533],\n",
       "       [0.75166273],\n",
       "       [0.56071658]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9065.703952590138"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test, color = 'red', label = 'Real Google Stock Price')\n",
    "plt.plot(y_pred, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
